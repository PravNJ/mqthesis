\chapter{Developing a Framework for Classification}

The volume and complexity of large spectroscopic datasets pose a significant challenge for developing methods to identify and classify emission-line stars. As previously explored, these and other constraints indicated that it would not be efficient or an effective use of time to trial multiple machine learning methods in pursuit of the end goals. As a result, a general framework and set of principles was developed based on the background provided in Chapters 1 to 3. These principles guided the development of a viable prototype method upon which the total machine learning method was built. The details of this framework, the methods that were selected, the {\em raison d'Ãªtre} for these decisions and the results from the prototype are presented in the following sections.

\section{Requirements and Constraints}

As shown in prior chapters, morphological classification based on visual inspection of spectra cannot scale feasibly with the volume of data present in GALAH DR3. And while machine learning methods such as t-SNE and autoencoders \citep{traven2017galah, vcotar2021galah} have been relatively successful in detecting H$\alpha$ emission spectra, neither technique is able to further classify emission-line spectra into classes, such as P Cygni and inverse P Cygni.

When developing a framework for classification, it was found that an approach that is sensitive to the meaningful morphological differences between P Cygni, inverse P Cygni and other species is an important requirement. Given that the feature space is of size $\sim$ \num[round-precision=2,round-mode=figures, scientific-notation=true]{2928752091}, a classification method must be able to overcome the "curse of dimensionality" and be computationally and memory efficient. Feature engineering must capture the understanding that P Cygni spectra exhibit a redshifted emission peak, while the inverse P Cygni spectra exhibit a blueshifted peak. A method should also be able to differentiate between classes such as double-peaked emission spectra and emission lines superimposed on absorption. This can be quite intuitive for a human being to do manually, but can prove challenging for a machine, since it must be trained on a well-constructed training data set that is sensitive to these features. 

Given that DR3 does not have labeled samples of P Cygni and inverse P Cygni spectra, a supervised learning approach to classification was not suitable. This narrowed the approach to the unsupervised learning domain \citep{hastie2009elements}. Chapter 2 demonstrated that well-known unsupervised clustering methods such as k-means clustering generally fail to cluster and classify emission-line spectra \citep{garcia2018machine}. Given this result, this and related methods were not given further consideration. Instead, a first principles-based approach was adopted, with a focus on methods that are sensitive to morphological similarities and differences between spectra. More rudimentary methods, such as cross-correlation of signals, are examples of methods that could be sensitive to the various emission line morphologies. However, given that a labeled data set of the various classes of emission-line spectra in DR3 did not exist, this line of inquiry was abandoned as it was not possible to create mean spectra for convolving against all DR3 spectra for the various potential classes. Instead, methods were explored that created effects similar to pairwise cross correlation, provided a similarity score (or equivalent) with limited human intervention, and had minimum reliance on rule-based approaches that have been used in the past \citep{traven2015gaia}. 

These constraints narrowed the search for suitable methods to a field known as unsupervised time series clustering, more specifically a clustering method based on a concept used extensively in signal processing called dynamic time warping (DTW) \citep{kruskal1983overview}. First introduced in 1975 as an algorithm for speech recognition \citep{itakura1975minimum}, DTW has been modified and adapted extensively in various scientific disciplines such as signal processing, telecommunications and biomedical engineering. It was demonstrated in Chapter 2 that DR3 spectra, and indeed all spectra, are mathematically analogous to time series; while an individual spectrum does not contain a time axis, the monotonically-increasing wavelength grid serves as the analogue of the time axis. Time series methods such as DTW have been more generally developed in the domain of time series analysis \citep{nielsen2019practical} and can be suitably adapted to stellar spectra. With clustering, this work did not rely on labelled data, but rather took a data-driven approach that learns from the emission-line morphologies present in the normalised spectral data present in DR3.

\section{Dynamic Time Warping}

Dynamic time warping (DTW) is a time-series analysis algorithm that can measure similarity between two temporal sequences. The similarity can then be used to cluster morphologically similar spectra into meaningful groups. These clusters can then be used to classify spectra into distinct classes. 

DTW is suitable for clustering problems where the morphology of the signal plays a salient role over other features \citep{nielsen2019practical} and where labeled data are unavailable. The name is inspired by the method itself, in which two signals are stretched or warped to align them on the temporal axis. For stellar spectra, this warping takes place in the wavelength domain and thus produces a discrete dynamic {\em wavelength} warping effect.

\begin{figure}[!htb]
\centering
\includegraphics[scale=1]{figures/Dynamic_time_warping.png}
\caption{Each point on the wavelength grid is mapped to a point on the opposite spectrum, but there is no requirement that the mapping is one to one. Reproduced from \citet{nielsen2019practical}}
\label{fig4.1}
\end{figure}

As indicated in Figure \ref{fig4.1}, the algorithm works by expanding or contracting the wavelength axis to find the best alignment and thus ensuring that morphologically similar spectra can be compared. This algorithm is often described as being similar to comparing the shape of signals visually. The algorithm follows several steps and has several constraints which are as follows:

\begin{enumerate}
    \item Every point on the spectrum must be matched with at least one point of the other spectrum
    \item The first and last indices of each spectrum must be matched with their counterparts in the other spectrum
    \item The mapping must be such that the wavelength is increasing rather than decreasing, i.e. the method should not match a point on one spectrum to a point on the other spectrum that has passed. 
\end{enumerate}

Steps 2 and 3 do not have a significant impact on the dataset being used in this work as the data are sampled to the same wavelength grid and the spectra are thus of equal length. 
There are many possible ways to align two spectra while adhering to these constraints. The algorithm chooses the alignment that minimises the distance between the spectra. This distance is a cost function and is measured as the sum of the absolute differences between matched points. The absolute difference in this context is the difference between the points' values (wavelength values). This distance measure then serves as the basis for clustering.


The Pythonic representation of this algorithm is as follows:

\begin{lstlisting}[language=Python]
# Primary function
def distDTW(lambda1, lambda2):
     DTW={}
     for i in range(len(lambda1)):
         DTW[(i, -1)] = np.inf
     for i in range(len(lambda2)):
         DTW[(-1, i)] = np.inf
     DTW[(-1, -1)] = 0
 
# Calculate the optimum i.e. where distance is minimum
     for i in range(len(lambda1)):
         for j in range(len(lambda2)):
             dist = (lambda1[i] - lambda2[j])**2
             DTW[(i, j)] = dist + min(DTW[(i-1, j)],
                                      DTW[(i, j-1)], 
                                      DTW[(i-1, j-1)])
 
 # Return the associated distance between two spectra
     return sqrt(DTW[len(lambda1)-1, len(lambda2)-1])
\end{lstlisting}

Despite the effectiveness of this algorithm, the computational complexity is still of order $O(N^2)$. As this presents a significant computational cost and overhead, the method developed here relies on a linear time complexity approximation  -- i.e., the $O(N)$ Python language implementation of DTW called \texttt{FastDTW} -- to compute the optimum distance between spectra and thus the similarity \citep{salvador2007toward}. %\texttt{FastDTW} is a linear approximation to the DTW method above. 
(A full discussion of how \texttt{FastDTW} compares to other implementations of DTW is beyond the scope of this thesis.)

In addition to computational complexity, an important consideration is available memory. Generally, all spectral data must be loaded into memory (RAM) when computing DTW distances. In the case of DR3, this implies holding $\sim$ \num[round-precision=2,round-mode=figures, scientific-notation=true]{2928752091} features in memory. The computational hardware available for this project had a memory capacity of $\sim$ 300 GB. \texttt{FastDTW} in particular required a memory capacity of at least 1TB for the $\sim$ \num[round-precision=2,round-mode=figures, scientific-notation=true]{2928752091} features. This is a significant amount of data to hold in memory and presented a serious obstacle.

Two strategies were developed to overcome these challenges and reduce computational and memory overheads. These are as follows:

\begin{enumerate}
    \item Reduce the number of features. As explained in a Chapter 2, only the region around H$\alpha$ is pre-selected in this work, and \texttt{FastDTW} was run only on this region.
    \item Reduce the search space from the entire DR3 data set to a subset which has a higher chance of yielding P Cygni, inverse P Cygni and other emission-line spectra. The existence of H$\alpha$ emission-line spectra is effectively a precursor to the existence of P Cygni and inverse P Cygni spectra. Thus the H$\alpha$ emission-line data set from \citet{vcotar2021galah} was used for prototyping this method. This subset with $\sim$ 10,000 spectra includes data from GALAH and other related surveys with the HERMES spectrograph. It is assumed that this data set only contains H$\alpha$ emission-line spectra, although  \citet{vcotar2021galah} have indicated that this data set  could contain non-emission-line (``typical'') spectra as well, albeit as a comparatively minor proportion. 
\end{enumerate}

There are many machine learning methods that can be used to cluster groups of similar and dissimilar observations. These methods will generally compute method-specific distance measures as a similarity metric. DBSCAN, for example, computes a method-specific distance which cannot be overridden by a pre-computed distance metric such as a DTW distance \citep{traven2017galah}. It is unclear whether a DBSCAN distance metric, or indeed a distance metric other than DTW, can capture the morphological features of emission-line stars. Due to time constraints, a thorough evaluation of the alternative distance metrics provided by the various clustering methods available was not undertaken. Instead, a clustering method which can accommodate pre-computed distances was chosen: agglomerative hierarchical clustering. 

\section{Agglomerative Hierarchical Clustering}

Agglomerative hierarchical clustering is a method that can take a pre-computed distance metric such as a DTW distance, and use it to cluster observations into classes. It is a well-understood and robust method that has proven to work well on time series problems relying on DTW distances \citep{nielsen2019practical}.

With a similarity measure such as the pairwise DTW distances between spectra, hierarchical clustering can be used to group similar spectra into similar clusters. Once a similarity measure (or a dissimilarity measure) has been specified, hierarchical clustering produces a representation in which clusters at each level of the hierarchy are created by merging clusters at the next lower level. At the lowest level, each cluster contains a single observation. At the highest level, there exists a single cluster that contains all of the data \citep{hastie2009elements}. There are two basic paradigms to traverse these levels (or tree), namely, aggolomerative (bottom-up) and divisive (top-down). 

With agglomerative clustering, each spectrum will initially form a singleton cluster. At each step, the most similar spectra will be merged into a single cluster, producing one less cluster at the next higher level. The similarity between two spectra is based on the pre-computed DTW distance between them. A lower distance implies a greater similarity, while a higher distance indicates a dissimilarity.  

Based on the similarity (and dissimilarity) between individual spectra, a cluster dissimilarity can also be defined. Consider two clusters called $A$ and $B$. The dissimilarity between the two clusters $d(A,B)$ is computed from the set of pairwise dissimilarities $d_{ij}$, where one member of the pair, $i$, is in $A$ and the other, $j$, is in $B$. The complete linkage dissimilarity between the two clusters is set to be the dissimilarity of the furthest (most dissimilar) pair of spectra,
\begin{equation}
    d(A,B) = \max_{\substack{i \in A \\ j \in B}} d_{ij}
\end{equation}

This is also known as the farthest neighbour method. Other dissimilarity measures such as \emph{single linkage dissimilarity} or nearest neighbour dissimilarity can be defined as
\begin{equation}
    d(A,B) = \min_{\substack{i \in A \\ j \in B}} d_{ij}
\end{equation}

Hierarchical clusters can be visualised using a dendogram. A dendogram is a binary tree that represents the recursive agglomeration (or division) of clusters. The height of the tree (or a branch) is proportional to the inter-group dissimilarity defined above. 

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{figures/complete linkage.png}
\caption{Dendograms for a given toy data set using different similarity measures. Note the longer branch lengths of the complete linked tree that selects for maximum dissimilarity. Reproduced from \citet{hastie2009elements}.}
\end{figure}

This work used the complete linkage dissimilarity to cluster spectral groups. The justification for using this measure over the single linkage dissimilarity is to force the separation of P Cygni and inverse P Cygni spectra into distinct groups by exploiting the maximum distance between two individual spectra that belong to these groups. Other distance measures such as group average clustering use the average dissimilarity between groups. Group average clustering can be less accurate in separating the data into clusters as it relies on an average spectrum per cluster, which may not completely capture the variation of spectral morphologies within a cluster. Therefore this measure was not considered, as it may be less accurate in separating P Cygni from inverse P Cygni and other emission-line spectra due to this averaging or smoothing effect. This work also relies on the agglomerative (bottom-up) method, as it is more robust and has been studied extensively in the literature compared to the divisive (top-down) method \citep{hastie2009elements}.

\subsection{Selecting the Number of Clusters}

Given that the framework proposed above is an entirely unsupervised machine learning approach, it is generally not required that the number of clusters be specified in advance. In the absence of a predefined value for this parameter, the typical approach would require a plot of the dendogram where suitable cuts can be made at a required level. However, since the tree can theoretically be cut at any level, and can have a maximum number of clusters equal to the number of samples and a minimum number of clusters equal to 1, a more meaningful and reliable cut can be made with the aide of astrophysical domain knowledge, as will be demonstrated below, . In the absence of such knowledge, this work would have to cut the dendogram at each level, examine the clusters and subsequently decide on a suitable number of clusters. Furthermore, given that the sample size is at least 10,000 spectra, visually inspecting a dendogram for this data set can be challenging. Where possible, this work used prior art such as \citet{reipurth1996halpha}, \citet{traven2017galah}, and \citet{zhang2021catalog} to determine the number of clusters, thus eliminating the requirement to visually inspect a complex dendogram of the order of thousands of branches. 

Classes of H$\alpha$ emission-line spectra have been found using manual methods and as such, prior work can provide some guidance regarding the number of clusters. \citet{reipurth1996halpha}, in particular, proposed the existence of seven morphological groups which include P Cygni and inverse P Cygni, as well as five other H$\alpha$ emission-line classes \citep{reipurth1996halpha}. However, if the number of clusters is set to a value of two, there is a significant risk that other morphologies will be included in the P Cygni cluster and inverse P Cygni cluster, thus leading to erroneously classified/labelled clusters. Thus, based on the prior art, this work took the number of clusters to be between six and ten as a suitable range. The number of samples were significantly higher than any data sets in prior art, especially the manual classification approaches detailed in the prior chapters. The justification to use a higher number of clusters such as ten is to account for the possibility of additional morphological classes that may have been missed in the prior art during manual classification. As it will be demonstrated in Chapter 6, this over-classification can be beneficial when working with more complex data sets.

\section{Results}

The results of the DTW distance calculation can be visualised as a distance cost plot. Figure \ref{fig4.3} includes the pairwise distances for 6,977 samples from DR3 that are present in the \citeauthor{vcotar2021galah} data set after the application of DTW. Note that the plot resembles a triangular matrix with the diagonal representing a value of zero for the self distance of a spectrum. Lower values indicate higher similarity while higher distance values indicate lower similarity (or greater dissimilarity). Zooming in to a region reveals further structure concerning similar and dissimilar spectra. The zero distance diagonal and the triangular nature of the distance matrix, are visible on this plot.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{figures/dtw cotar.png}
\caption{Pairwise DTW distances for spectral samples in \citet{vcotar2021galah}.}
\label{fig4.3}
\end{figure}

This distance matrix was used as the basis for complete linkage aggolomerative hierarchical clustering. The number of clusters was varied between seven and ten. A mean silhouette score was calculated for each selection. This score was used as an additional selection criterion for the number of clusters. Silhouette scores can range between -1 and 1. Negative scores indicate that samples may be assigned to the wrong cluster. Values extremely close to zero indicate that clusters may overlap. The best achievable value is 1, although this is rarely achieved in practical unsupervised clustering problems of this nature. Thus the silhouette score is a measure of the efficacy of the clustering process.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.60]{figures/dtw cotar zoomed.png}
\caption{Pairwise DTW distances for spectral samples in \citet{vcotar2021galah} (zoomed).}
\end{figure}

In order to calculate the mean silhouette score, silhouette coefficients for all samples must be calculated as follows:

Compute the mean within-cluster distances given by $a$ and then compute the mean nearest-cluster distance $b$ for each sample. The sample silhouette coefficient is then given by

\begin{equation}
\frac{(b-a)}{\max_{}(a,b)}
\end{equation}

Once the coefficient for each sample was calculated, the mean silhouette score for the entire sample was computed. Table \ref{table:Silhouette Score} summarises the scores obtained.

\begin{table}[]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Number of Clusters} & \textbf{Silhouette Score} \\ \hline
6                     & 0.2904                    \\ \hline
7                     & 0.3033                    \\ \hline
8                     & 0.3005                    \\ \hline
9                     & 0.3092                    \\ \hline
10                    & 0.3044                    \\ \hline
\end{tabular}
\caption{Silhouette score comparison}
\label{table:Silhouette Score}
\end{center}
\end{table}

At face value it appears that nine clusters is the optimum, given that this produces the largest silhouette score. However, upon closer examination it was concluded that ten was more suitable under the essential constraint that P Cygni and inverse P Cygni spectra should be adequately separated from other clusters. Thus, the spectra that belong to each cluster for both nine clusters and ten clusters were plotted. For nine clusters, while a P Cygni-only cluster was identified, a cluster containing only inverse P Cygni spectra was not identified. However when this parameter was set to ten, two clear clusters of P Cygni and inverse P Cygni spectra were identified.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/pcygni.png}
\caption{102 P Cygni spectra identified using clustering.}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/inverse p cygni.png}
\caption{62 Inverse P Cygni spectra identified using clustering.}
\label{fig4.6}
\end{figure}

Eight other clusters with various emission-line morphologies, such as double peak emission, were also identified. Other classes are presented in the Appendix. Given the silhouette score, it is possible that some P Cygni and inverse P Cygni spectra may have been mis-classified (see Figure \ref{fig4.6}) and included in other classes. This can be addressed by further sub-clustering and classifying spectra via a second pass of the scheme above. This work, however, did not progress with multiple passes of this method due to time constraints. 

A sub-classification of the P Cygni and inverse P Cygni classes discovered in this process is presented in Chapter 5, where these results are compared to t-SNE. The advantages and disadvantages of this approach compared to t-SNE are discussed further in that chapter. 

\section{Line Fitting}

The P Cygni and inverse P Cygni spectra thus classified were modeled using a double Gaussian, with an offset for one of the Gaussian functions \citep{traven2015gaia, zhang2021catalog}. This mixture model with two Gaussians can be used to fit the line profile of P Cygni and inverse P Cygni spectra. Given that there are 102 P Cygni spectra that require fitting, this work adopted a semi-automated method where the initial conditions for the model parameters were driven by the data. Notably the minimum and maximum local flux values were used to set both the amplitude and mid-value of each peak and trough.

This work then utilised the popular Python based numerical optimisation package, \texttt{scipy} \citep{2020SciPy-NMeth} to generate fitted models for the P Cygni and inverse P Cygni spectra using least squares optimisation.

The Gaussian mixture model is defined as, 

\begin{equation}
    f(x) = \frac{A}{\sigma_1\sqrt{2\pi}} 
  \exp\left( -\frac{1}{2}\left(\frac{x-\mu_1}{\sigma_1}\right)^{\!2}\,\right) + \frac{B}{\sigma_2\sqrt{2\pi}} 
  \exp\left( -\frac{1}{2}\left(\frac{x-\mu_2}{\sigma_2}\right)^{\!2}\,\right) + C
\end{equation}


This seven parameter model contains an offset parameter $C$ to account for the inverted Gaussian required to model the absorption trough/line of the P Cygni and inverse P Cygni spectra. The parameters A and B are to account for the respective amplitudes of the emission and absorption lines. The uncertainties of this fit can be modelled more accurately within a Bayesian framework and the use of MCMC estimation \citep{hogg2010data}. A thorough discussion of this framework and estimation method is, however, beyond the scope of this work.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/p cugni fitted.png}
\caption{A Gaussian mixture model fit of one of the identified P Cygni spectra.}
\end{figure}

The line-fitting method described can be repeated for each P Cygni spectrum discovered by clustering. Presented below are a few examples of these fitted models. This technique can also extended to the inverse P Cygni spectra.

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/p cygni fitted 2.png}
\caption{A Gaussian mixture model fit for sobject ID 140117002101365. }
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/p cygni fitted 3.png}
\caption{A Gaussian mixture model fit for sobject ID 140414005101301. }
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/inverse p cygni 1.png}
\caption{A Gaussian mixture model fit of one of the identified inverse P Cygni spectrum. }
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.45]{figures/inverse p cygni fitted 2.png}
\caption{A Gaussian mixture model fit for one of the identified inverse P Cygni spectrum.}
\end{figure}

\section{Concluding Remarks}

Once a framework was developed, the sample data provided by \citet{vcotar2021galah} significantly accelerated the development of the methods discussed above. The primary reason for this is that methods can be tested and iterated at a more rapid pace given that the sample size was significantly smaller than GALAH DR3. Additionally, the sample data was well-pruned and presumably only consisted of emission-line spectra, although this sample purity may not be guaranteed. These conclusions make a strong case for the availability of open access data and code.

Dynamic time warping and dynamic \emph{wavelength} warping were able to learn from the data presented and provide pairwise distances that can capture the morphologies of the spectra. Combined with agglomerative hierarchical clustering, DTW can form the basis of a machine learning method that can identify, cluster and classify P Cygni, inverse P Cygni and other types of emission-line spectra.

Compared to methods such as k-means, logistic regression and t-SNE presented in Chapter 2, it can be argued that DTW is more sensitive to the morphological differences and similarities between spectra. In Chapter 2 t-SNE was introduced as a method to identify H$\alpha$ emission-line spectra in GALAH. Given the efficacy of DTW on a set of emission-line spectra provided by \citename{vcotar2021galah} this work considered whether t-SNE can be used as a pre-processing step in identifying emission-line stars prior to applying DTW. This hypothesis was tested, and the results are presented in the next chapter. 








